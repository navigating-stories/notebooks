{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadcfb6a",
   "metadata": {},
   "source": [
    "# Multilingual Digital Story Grammar\n",
    "\n",
    "In this notebook, we aim to implement a version of Digital Story Grammar (DSG; Bastholm Andrade & Andersen; [link](https://www.tandfonline.com/doi/abs/10.1080/13645579.2020.1723205)) that works with multiple languages (in particular Dutch, German, Danish, and English). The code will interface to the spaCy NLP library that has pretrained and easy-to-use pipelines for many languages available.\n",
    "\n",
    "The goal of the method is to extract the subject (actor), main verb (action), and object of each sentence or phrase. In DSG, these are referenced as *narrative units* and enable the construction of character networks. This notebook will use spaCy's `DependencyMatcher` to extract patterns in dependency relations of each sentence. However, each language has somewhat different dependency relations so it requires a specific set of patterns to be matched. German in particular uses a completely different notation for dependency relations, so it requires entirely different patterns that the other three languages (see this [link](https://www.ims.uni-stuttgart.de/documents/ressourcen/korpora/tiger-corpus/annotation/tiger_scheme-syntax.pdf) for the notation scheme). \n",
    "\n",
    "The patterns for each language are store in a separate `multilingual_dsg_patterns_xx.json` file. The pattern files consist of a nested list of dictionaries `[[{}, {}, ...], ...]`. Each list of dictionaries `[{},{}, ...]` represents a pattern of dependency relations that will be matched. Each dictionary in the list represents a token that is part of the dependency relations pattern. The first dictionary in each pattern has usually two entries: `RIGHT_ID` indicating a name for the token in the pattern; and `RIGHT_ATTRS` listing the required attributes of the token for a match (e.g., `{\"DEP\": \"nsubj\"}` means that the token must be a subject in a phrase). There can be `OR` or `NOT` type matches by using `IN` or `NOT_IN` keys for dictionaries (see the pattern files for examples). Subsequent dictionaries in a pattern have two additional entries: `LEFT_ID` which refers to another token in the parsing tree to which the current token is related; and `REL_OP` specifying the relation between the other token and the token to be matched. An overview of possible relations is presented on https://spacy.io/api/dependencymatcher. For example `REL_OP: >` indicates a match when the `LEFT_ID` token is the head of the `RIGHT_ID` token in the parsing tree.\n",
    "\n",
    "Example:\n",
    "```\n",
    "[\n",
    "  {\n",
    "    \"RIGHT_ID\": \"verb\",\n",
    "    \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\", \"AUX\"]}}\n",
    "  },\n",
    "  {\n",
    "    \"LEFT_ID\": \"verb\",\n",
    "    \"REL_OP\": \">\",\n",
    "    \"RIGHT_ID\": \"subj\",\n",
    "    \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"}\n",
    "  },\n",
    "  {\n",
    "     \"LEFT_ID\": \"verb\",\n",
    "     \"REL_OP\": \">>\",\n",
    "     \"RIGHT_ID\": \"obj\",\n",
    "     \"RIGHT_ATTRS\": {\"DEP\": \"pobj\"}\n",
    "  }\n",
    "]\n",
    "\n",
    "if a word has POS tag VERB or AUX and\n",
    "   the word has an immediate dependent (DEP) word with relation nsubj and\n",
    "   the word has a dependent (DEP) word with relation pobj \n",
    "then word1 is a verb, word2 is a subj and word3 is an obj \n",
    "```\n",
    "\n",
    "A sentence or phrase can have multiple matches for a pattern (i.e., multiple objects or conjuncts), and for each match a row is added to the output table.\n",
    "\n",
    "A step-by-step example can also be found on https://spacy.io/api/dependencymatcher.\n",
    "\n",
    "A list of the universal dependency tags is here: https://universaldependencies.org/docs/en/dep/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815cdb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Multilingual Digital Story Grammar \"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import warnings\n",
    "# Change this to use different language as example; see spacy.io/models\n",
    "from spacy.lang.en.examples import sentences as en_sentences\n",
    "from spacy.lang.nl.examples import sentences as nl_sentences\n",
    "from spacy.lang.de.examples import sentences as de_sentences\n",
    "from spacy.lang.da.examples import sentences as da_sentences\n",
    "from spacy.matcher import DependencyMatcher\n",
    "from spacy import displacy\n",
    "\n",
    "if spacy.__version__ < \"3\":\n",
    "    warnings.warn(\n",
    "        \"Module 'spacy' should be version >= 3.0 to run this notebook without errors\")\n",
    "if pd.__version__ < \"1.0\":\n",
    "    warnings.warn(\n",
    "        \"Module 'pandas' should be version >= 1.0 to run this notebook without errors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f0b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_SPACY_PIPELINE = \"en_core_web_sm\"\n",
    "EN_DEPENDENCY_PATTERN_FILE = \"multilingual_dsg_patterns_en.json\"\n",
    "\n",
    "NL_SPACY_PIPELINE = \"nl_core_news_sm\"\n",
    "NL_DEPENDENCY_PATTERN_FILE = \"multilingual_dsg_patterns_nl.json\"\n",
    "\n",
    "DE_SPACY_PIPELINE = \"de_core_news_sm\"\n",
    "DE_DEPENDENCY_PATTERN_FILE = \"multilingual_dsg_patterns_de.json\"\n",
    "\n",
    "DA_SPACY_PIPELINE = \"da_core_news_sm\"\n",
    "DA_DEPENDENCY_PATTERN_FILE = \"multilingual_dsg_patterns_da.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d44cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a few test sentences\n",
    "examples = [\n",
    "    \"The bird flew over the roof.\",\n",
    "    \"The cow ate the grass. The goat watched the cow.\",\n",
    "    \"The cow ate the grass while the goat watched the cow.\",\n",
    "    \"The goat watched the cow which was eating grass.\",\n",
    "    \"The goat attempted eating the cow's grass.\",\n",
    "    \"The cow ate grass, the cow ate butter.\",\n",
    "    \"The cow and the goat ate grass.\",\n",
    "    \"The grass was eaten by the cow, the goat and the bird.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c32ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy_pipeline(name):\n",
    "    \"\"\"Check if the spacy language pipeline was downloaded and load it.\n",
    "    Downloads the language pipeline if not available.\n",
    "\n",
    "    Args:\n",
    "        name (string): Name of the spacy language.\n",
    "\n",
    "    Returns:\n",
    "        spacy.language.Language: The spacy language pipeline\n",
    "    \"\"\"\n",
    "    if spacy.util.is_package(name):\n",
    "        nlp = spacy.load(name)\n",
    "    else:\n",
    "        os.system(f\"spacy download {name}\")\n",
    "        nlp = spacy.load(name)\n",
    "    return nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd80a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dict_in_list(dict_obj, dict_list):\n",
    "    \"\"\"Check if a dictionary (partially) matches a list of dictionaries.\n",
    "\n",
    "    Note: This function is used to avoid duplicate matches (e.g., Subj+Verb in Subj+Verb+Obj)\n",
    "\n",
    "    Args:\n",
    "        dict_obj (dict): A dictionary object.\n",
    "        dict_list (list): A list of dictionary objects.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all non-empty items in dict_obj match the items in any dictionary objects in dict_list, otherwise False.\n",
    "    \"\"\"\n",
    "    if dict_obj in dict_list:\n",
    "        return True\n",
    "\n",
    "    check = [False] * len(dict_obj.keys())\n",
    "\n",
    "    for i, key in enumerate(dict_obj.keys()):\n",
    "        if str(dict_obj[key]) == \"_\":\n",
    "            check[i] = True\n",
    "            next\n",
    "        else:\n",
    "            for ref_dict in dict_list:\n",
    "                if dict_obj[key].i == ref_dict[key].i:\n",
    "                    check[i] = True\n",
    "                    break\n",
    "\n",
    "    return all(check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ef03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_matches(doc, matches, matcher, nlp, keys):\n",
    "    \"\"\"Extract the matched tokens for selected keys.\n",
    "\n",
    "    Args:\n",
    "        doc (spacy.tokens.Doc): A spacy doc object as returned by a spacy language pipeline.\n",
    "        matches (list): A list of (match_id, token_ids) tuples as returned by a spacy dependency matcher.\n",
    "        matcher (spacy.matcher.DependencyMatcher): A spacy dependency matcher object.\n",
    "        nlp (spacy.language.Language): A spacy language pipeline.\n",
    "        keys (list): A list of keys to which the dependcy matches are assigned.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries that each contain a match of the dependency matcher. \n",
    "            Has the same keys as the `keys` argument. Empty keys contain a spacy token with text='_'.\n",
    "    \"\"\"\n",
    "    matches_list = []\n",
    "\n",
    "    for l, (match_id, token_ids) in enumerate(matches):\n",
    "        match_dict = {}\n",
    "\n",
    "        for key in keys:\n",
    "            match_dict[key] = nlp(\"_\")[0]\n",
    "            \n",
    "        for k, token_id in enumerate(token_ids):\n",
    "            key = matcher.get(match_id)[1][0][k][\"RIGHT_ID\"]\n",
    "            if key in match_dict.keys():\n",
    "                match_dict[key] = doc[token_id]\n",
    "\n",
    "        if not check_dict_in_list(match_dict, matches_list):\n",
    "            match_dict[\"match_id\"] = match_id\n",
    "            matches_list.append(match_dict)\n",
    "\n",
    "    return matches_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fffc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matcher(nlp, pattern_file):\n",
    "    \"\"\"Create a spacy dependency matcher.\n",
    "\n",
    "    Args:\n",
    "        nlp (spacy.language.Language): A spacy language pipeline.\n",
    "        pattern_file (str): The path to the dependency pattern .json file for the matcher.\n",
    "\n",
    "    Returns:\n",
    "        spacy.matcher.DependencyMatcher: A spacy dependency matcher object.\n",
    "    \"\"\"\n",
    "    matcher = DependencyMatcher(nlp.vocab, validate=True)\n",
    "\n",
    "    with open(pattern_file, \"r\") as file:\n",
    "        patterns = json.load(file)\n",
    "\n",
    "    for i, pattern in enumerate(patterns):\n",
    "        matcher.add(i, [pattern])\n",
    "\n",
    "    return matcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e6723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children_ids(token, children_deps, ids):\n",
    "    for child in token.children:\n",
    "        if child.dep_ in children_deps:\n",
    "            ids.append(child.i)\n",
    "            ids = get_children_ids(child, children_deps, ids)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e99bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_children_deps(token, doc, children_deps):\n",
    "    \"\"\"Append children to a token based on dependency tag.\n",
    "\n",
    "    Note: This function is used to append words of a noun compound.\n",
    "\n",
    "    Args:\n",
    "        token (spacy.token.Token): A spacy token object.\n",
    "        doc (spacy.token.Doc): A spacy doc object that includes the token.\n",
    "        children_deps (list): A list of dependency tags.\n",
    "\n",
    "    Returns:\n",
    "        spacy.token.Token: A span of spacy tokens (token argument plus children with specified dependency tags) \n",
    "        if token argument is non-empty, the token argument otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    if str(token) != \"_\":\n",
    "        children_match_idx = get_children_ids(token, children_deps, [token.i])\n",
    "        span = doc[min(children_match_idx):max(children_match_idx)+1]\n",
    "\n",
    "        return span\n",
    "    else:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "243ae20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_object_verb_table(docs, nlp, matcher, keys=[\"verb\", \"subj\", \"obj\", \"comp\", \"prep\", \"aux\", \"subjadj\", \"objadj\", \"obl\", \"case\", \"case_arg\", \"objfixed\", ]):\n",
    "    \"\"\"Construct a pandas dataframe with subjects, verbs, and objects per sentence of documents.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of text strings.\n",
    "        nlp (spacy.language.Language): A spacy language pipeline.\n",
    "        matcher (spacy.matcher.DependencyMatcher): A spacy dependency matcher object.\n",
    "        keys (list): A list of keys to which the dependency matches are assigned. \n",
    "            Defaults to subjects, verbs, and objects.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe with a row for each match of the dependency matcher and cols:\n",
    "            doc_id (str): Index of the document in the document list.\n",
    "            sent_id (str): Index of the sentence in the document.\n",
    "            sent (spacy.tokens.Span): A spacy span object with the sentence.\n",
    "            match_id (str): Index of the match in the sentence.\n",
    "\n",
    "            For each key in the `keys` argument:\n",
    "                key (spacy.tokens.Token): A spacy token object that matches the dependency matcher patterns.\n",
    "    \"\"\"\n",
    "    docs_piped = nlp.pipe(docs)\n",
    "        \n",
    "    table_dict = {\n",
    "        \"doc_id\": [],\n",
    "        \"sent_id\": [],\n",
    "        \"sent\": [],\n",
    "        \"match_id\": [],\n",
    "        \"subj\": [],\n",
    "        \"verb\": [],\n",
    "        \"obj\": [],\n",
    "        \"comp\": [],\n",
    "        \"prep\": [],\n",
    "        \"aux\": [],\n",
    "        \"subjadj\": [],\n",
    "        \"objadj\": [],\n",
    "        \"obl\": [],\n",
    "        \"case\": [],\n",
    "        \"case_arg\": [],\n",
    "        \"objfixed\": [],\n",
    "    }\n",
    "\n",
    "    for i, doc in enumerate(docs_piped): # i: doc index\n",
    "        if DEBUG:\n",
    "            for token in doc:\n",
    "                print(token, token.pos_, token.dep_, token.head)\n",
    "        for j, sent in enumerate(doc.sents): # j: sent index\n",
    "            matches = matcher(sent)\n",
    "            matches_list = extract_matches(\n",
    "                sent, matches, matcher, nlp, keys=keys)\n",
    "            for l, match in enumerate(matches_list): # l: match index\n",
    "                table_dict[\"doc_id\"].append(str(i))\n",
    "                table_dict[\"sent_id\"].append(str(j))\n",
    "                table_dict[\"sent\"].append(sent.text)\n",
    "                table_dict[\"match_id\"].append(str(match[\"match_id\"]))\n",
    "\n",
    "                for key in keys:\n",
    "                    table_dict[key].append(append_children_deps(match[key], doc, [\"compound\", \"flat\"]))\n",
    "\n",
    "                    # Check for conjuncts, and add table row for each\n",
    "                    for conj in match[key].conjuncts:\n",
    "                        table_dict[\"doc_id\"].append(str(i))\n",
    "                        table_dict[\"sent_id\"].append(str(j))\n",
    "                        table_dict[\"sent\"].append(sent.text)\n",
    "                        table_dict[\"match_id\"].append(str(\"?\"))\n",
    "                        table_dict[key].append(conj)\n",
    "                        for key_conj in keys:\n",
    "                            if key != key_conj:\n",
    "                                table_dict[key_conj].append(match[key_conj])\n",
    "                if DEBUG:\n",
    "                    print(\"\")\n",
    "                                \n",
    "    for i in range(0, len(table_dict[\"comp\"])):\n",
    "        # insert table_dict[\"comp\"][i] in table_dict[\"verb\"][i]) here\n",
    "        pass\n",
    "    \n",
    "    return pd.DataFrame(table_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa42fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_character_network(sov_table_df):\n",
    "    \"\"\"Plots a subject-object-verb table as a character network. The edge weights are the sentiment scores of the verbs.\n",
    "\n",
    "    Args:\n",
    "        sov_table_df (pandas.DataFrame): A pandas data frame containing a subject, verb, and object token in each row\n",
    "\n",
    "    \"\"\"\n",
    "    sov_table_df[\"sentiment\"] = pd.Series([verb.sentiment for verb in sov_table_df[\"verb\"]], dtype=float)\n",
    "    sov_table_df[\"subj_text\"] = pd.Series([subj.text for subj in sov_table_df[\"subj\"]], dtype=str)\n",
    "    sov_table_df[\"obj_text\"] = pd.Series([obj.text for obj in sov_table_df[\"obj\"]], dtype=str)\n",
    "\n",
    "    char_net = nx.from_pandas_edgelist(\n",
    "        sov_table_df,\n",
    "        source=\"subj_text\",\n",
    "        target=\"obj_text\",\n",
    "        edge_attr=\"sentiment\"\n",
    "    )\n",
    "    \n",
    "    nx.draw_networkx(char_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6649909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_to_string(column):\n",
    "    new_column = []\n",
    "    for item in column:\n",
    "        new_column.append(str(item))\n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3eb925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_verb_group_column(result_table):\n",
    "    subjadj_column = []\n",
    "    objadj_column = []\n",
    "    rows_to_be_deleted = []\n",
    "    for i, row in result_table.iterrows():\n",
    "        subjadj_column.append(str(row[\"subjadj\"]))\n",
    "        objadj_column.append(str(row[\"objadj\"]))\n",
    "        if i > 0 and str(row[\"doc_id\"]) == str(result_table.loc[i-1][\"doc_id\"]) and str(row[\"subjadj\"]) != \"\":\n",
    "            subjadj_column[-2] += \" \" + str(row[\"subjadj\"])\n",
    "            rows_to_be_deleted.append(i)\n",
    "        if i > 0 and str(row[\"doc_id\"]) == str(result_table.loc[i-1][\"doc_id\"]) and str(row[\"objadj\"]) != \"\":\n",
    "            objadj_column[-2] += \" \" + str(row[\"objadj\"])\n",
    "            rows_to_be_deleted.append(i)\n",
    "    \n",
    "    result_table[\"subjadj\"] = subjadj_column\n",
    "    result_table[\"objadj\"] = objadj_column\n",
    "    for row_id in rows_to_be_deleted:\n",
    "        result_table = result_table.drop(row_id)\n",
    "    verb_group_column = []\n",
    "    subj_extended_column = []\n",
    "    obj_extended_column = []\n",
    "    means_column = []\n",
    "    for i, row in result_table.iterrows():\n",
    "        verb_group = str(row[\"verb\"])\n",
    "        subj_extended = str(row[\"subj\"])\n",
    "        obj_extended = str(row[\"obj\"])\n",
    "        means = \"\"\n",
    "        if str(row[\"aux\"]) != \"_\":\n",
    "            verb_group = str(row[\"aux\"]) + \" \" + verb_group\n",
    "        if str(row[\"prep\"]) != \"_\":\n",
    "            verb_group += \" \" + str(row[\"prep\"])\n",
    "        if str(row[\"comp\"]) != \"_\":\n",
    "            verb_group += \" \" + str(row[\"comp\"])\n",
    "        if str(row[\"subjadj\"]) != \"_\":\n",
    "            subj_extended = str(row[\"subjadj\"]) + \" \" + subj_extended\n",
    "        if str(row[\"objadj\"]) != \"_\":\n",
    "            obj_extended = str(row[\"objadj\"]) + \" \" + obj_extended\n",
    "        if str(row[\"objfixed\"]) != \"_\":\n",
    "            obj_extended = obj_extended + \" \" + str(row[\"objfixed\"])\n",
    "        if str(row[\"obl\"]) != \"_\" and str(row[\"case\"]) != \"_\":\n",
    "            means = str(row[\"case\"]) + \" \" + str(row[\"case_arg\"]) + \" \" + str(row[\"obl\"])\n",
    "        verb_group_column.append(verb_group)\n",
    "        subj_extended_column.append(subj_extended)\n",
    "        obj_extended_column.append(obj_extended)\n",
    "        means_column.append(means)\n",
    "    result_table[\"verb group\"] = verb_group_column\n",
    "    result_table[\"subj_extended\"] = subj_extended_column\n",
    "    result_table[\"obj_extended\"] = obj_extended_column\n",
    "    result_table[\"means\"] = means_column\n",
    "    result_table = result_table[[\"doc_id\", \"sent_id\", \"sent\", \"match_id\", \"subj_extended\", \"verb group\", \"obj_extended\", \"means\"]]\n",
    "    return result_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8d91f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows(result_table):\n",
    "    near_duplicate_successive_rows = {}\n",
    "    for i, row in result_table.iterrows():\n",
    "        if i > 0:\n",
    "            different_columns = []\n",
    "            for column_name in result_table.loc[i].keys():\n",
    "                if str(result_table.loc[i][column_name]) != str(result_table.loc[i-1][column_name]):\n",
    "                    different_columns.append(column_name)\n",
    "            if len(different_columns) == 1:\n",
    "                near_duplicate_successive_rows[i-1] = different_columns[0]\n",
    "    for i, row in result_table.iterrows():\n",
    "        if i in near_duplicate_successive_rows:\n",
    "            row[near_duplicate_successive_rows[i]] = str(row[near_duplicate_successive_rows[i]]) + \" \" + str(result_table.loc[i+1][near_duplicate_successive_rows[i]])\n",
    "    for i, row in result_table.iterrows():\n",
    "        if i-1 in near_duplicate_successive_rows:\n",
    "            result_table = result_table.drop(i)\n",
    "    return result_table.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff57bec",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "413a7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72112b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple is looking at buying U.K. startup for $1 billion',\n",
       " 'Autonomous cars shift insurance liability toward manufacturers',\n",
       " 'San Francisco considers banning sidewalk delivery robots',\n",
       " 'London is a big city in the United Kingdom.',\n",
       " 'Where are you?',\n",
       " 'Who is the president of France?',\n",
       " 'What is the capital of the United States?',\n",
       " 'When was Barack Obama born?',\n",
       " 'The quick brown fox jumps over the lazy dog.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_en = load_spacy_pipeline(EN_SPACY_PIPELINE)\n",
    "\n",
    "matcher_en = create_matcher(nlp_en, EN_DEPENDENCY_PATTERN_FILE)\n",
    "\n",
    "EXTRA_SENT = \"The quick brown fox jumps over the lazy dog.\"\n",
    "if EXTRA_SENT not in en_sentences:\n",
    "    en_sentences.append(EXTRA_SENT)\n",
    "en_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5431c9ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16062/93986386.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_subject_object_verb_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatcher_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp_en' is not defined"
     ]
    }
   ],
   "source": [
    "result_table = get_subject_object_verb_table(en_sentences, nlp_en, matcher_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6913c725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>match_id</th>\n",
       "      <th>subj</th>\n",
       "      <th>verb</th>\n",
       "      <th>obj</th>\n",
       "      <th>comp</th>\n",
       "      <th>prep</th>\n",
       "      <th>aux</th>\n",
       "      <th>subjadj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple is looking at buying U.K. startup for $1...</td>\n",
       "      <td>4</td>\n",
       "      <td>(Apple)</td>\n",
       "      <td>(looking)</td>\n",
       "      <td>(U.K.)</td>\n",
       "      <td>(buying)</td>\n",
       "      <td>(at)</td>\n",
       "      <td>(is)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonomous cars shift insurance liability towa...</td>\n",
       "      <td>0</td>\n",
       "      <td>(cars)</td>\n",
       "      <td>(shift)</td>\n",
       "      <td>(insurance, liability)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(Autonomous)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco considers banning sidewalk deliv...</td>\n",
       "      <td>3</td>\n",
       "      <td>(San, Francisco)</td>\n",
       "      <td>(considers)</td>\n",
       "      <td>(sidewalk, delivery, robots)</td>\n",
       "      <td>(banning)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>London is a big city in the United Kingdom.</td>\n",
       "      <td>7</td>\n",
       "      <td>(London)</td>\n",
       "      <td>(is)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Where are you?</td>\n",
       "      <td>7</td>\n",
       "      <td>(you)</td>\n",
       "      <td>(are)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the capital of the United States?</td>\n",
       "      <td>7</td>\n",
       "      <td>(capital)</td>\n",
       "      <td>(is)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>When was Barack Obama born?</td>\n",
       "      <td>5</td>\n",
       "      <td>(Barack, Obama)</td>\n",
       "      <td>(born)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(was)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>6</td>\n",
       "      <td>(fox)</td>\n",
       "      <td>(jumps)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(quick)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>6</td>\n",
       "      <td>(fox)</td>\n",
       "      <td>(jumps)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(brown)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id sent_id                                               sent match_id  \\\n",
       "0      0       0  Apple is looking at buying U.K. startup for $1...        4   \n",
       "1      1       0  Autonomous cars shift insurance liability towa...        0   \n",
       "2      2       0  San Francisco considers banning sidewalk deliv...        3   \n",
       "3      3       0        London is a big city in the United Kingdom.        7   \n",
       "4      4       0                                     Where are you?        7   \n",
       "5      6       0          What is the capital of the United States?        7   \n",
       "6      7       0                        When was Barack Obama born?        5   \n",
       "7      8       0       The quick brown fox jumps over the lazy dog.        6   \n",
       "8      8       0       The quick brown fox jumps over the lazy dog.        6   \n",
       "\n",
       "               subj         verb                           obj       comp  \\\n",
       "0           (Apple)    (looking)                        (U.K.)   (buying)   \n",
       "1            (cars)      (shift)        (insurance, liability)              \n",
       "2  (San, Francisco)  (considers)  (sidewalk, delivery, robots)  (banning)   \n",
       "3          (London)         (is)                                            \n",
       "4             (you)        (are)                                            \n",
       "5         (capital)         (is)                                            \n",
       "6   (Barack, Obama)       (born)                                            \n",
       "7             (fox)      (jumps)                                            \n",
       "8             (fox)      (jumps)                                            \n",
       "\n",
       "   prep    aux       subjadj  \n",
       "0  (at)   (is)                \n",
       "1               (Autonomous)  \n",
       "2                             \n",
       "3                             \n",
       "4                             \n",
       "5                             \n",
       "6        (was)                \n",
       "7                    (quick)  \n",
       "8                    (brown)  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39250848",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = combine_rows(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46a1e68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erikt/.local/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "result_table_combined = add_verb_group_column(result_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98adc2",
   "metadata": {},
   "source": [
    "For sentence 0, we would like `U.K. startup` as object but we cannot have it because the dependency parser classifies `startup` as a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a60d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>match_id</th>\n",
       "      <th>subj_extended</th>\n",
       "      <th>verb group</th>\n",
       "      <th>obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple is looking at buying U.K. startup for $1...</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>is looking at buying</td>\n",
       "      <td>U.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonomous cars shift insurance liability towa...</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonomous cars</td>\n",
       "      <td>shift</td>\n",
       "      <td>insurance liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco considers banning sidewalk deliv...</td>\n",
       "      <td>3</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>considers  banning</td>\n",
       "      <td>sidewalk delivery robots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>London is a big city in the United Kingdom.</td>\n",
       "      <td>7</td>\n",
       "      <td>London</td>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Where are you?</td>\n",
       "      <td>7</td>\n",
       "      <td>you</td>\n",
       "      <td>are</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the capital of the United States?</td>\n",
       "      <td>7</td>\n",
       "      <td>capital</td>\n",
       "      <td>is</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>When was Barack Obama born?</td>\n",
       "      <td>5</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>was born</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>6</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumps</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id sent_id                                               sent match_id  \\\n",
       "0      0       0  Apple is looking at buying U.K. startup for $1...        4   \n",
       "1      1       0  Autonomous cars shift insurance liability towa...        0   \n",
       "2      2       0  San Francisco considers banning sidewalk deliv...        3   \n",
       "3      3       0        London is a big city in the United Kingdom.        7   \n",
       "4      4       0                                     Where are you?        7   \n",
       "5      6       0          What is the capital of the United States?        7   \n",
       "6      7       0                        When was Barack Obama born?        5   \n",
       "7      8       0       The quick brown fox jumps over the lazy dog.        6   \n",
       "\n",
       "     subj_extended            verb group                       obj  \n",
       "0            Apple  is looking at buying                      U.K.  \n",
       "1  Autonomous cars               shift         insurance liability  \n",
       "2    San Francisco    considers  banning  sidewalk delivery robots  \n",
       "3           London                  is                              \n",
       "4              you                 are                              \n",
       "5          capital                  is                              \n",
       "6     Barack Obama            was born                              \n",
       "7  quick brown fox               jumps                              "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36fcd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc_id sent_id                                               sent match_id  \\\n",
      "0       0       0                       The bird flew over the roof.        7   \n",
      "1       1       0                             The cow ate the grass.        1   \n",
      "2       1       1                          The goat watched the cow.        1   \n",
      "3       2       0  The cow ate the grass while the goat watched t...        1   \n",
      "4       2       0  The cow ate the grass while the goat watched t...        1   \n",
      "5       2       0  The cow ate the grass while the goat watched t...        3   \n",
      "6       3       0   The goat watched the cow which was eating grass.        1   \n",
      "7       3       0   The goat watched the cow which was eating grass.        1   \n",
      "8       3       0   The goat watched the cow which was eating grass.        5   \n",
      "9       4       0         The goat attempted eating the cow's grass.        3   \n",
      "10      5       0             The cow ate grass, the cow ate butter.        1   \n",
      "11      5       0             The cow ate grass, the cow ate butter.        1   \n",
      "12      5       0             The cow ate grass, the cow ate butter.        3   \n",
      "13      6       0                    The cow and the goat ate grass.        1   \n",
      "14      6       0                    The cow and the goat ate grass.        ?   \n",
      "15      7       0  The grass was eaten by the cow, the goat and t...        2   \n",
      "16      7       0  The grass was eaten by the cow, the goat and t...        ?   \n",
      "17      7       0  The grass was eaten by the cow, the goat and t...        ?   \n",
      "\n",
      "       subj         verb       obj       comp prep    aux subjadj  \n",
      "0    (bird)       (flew)                                           \n",
      "1     (cow)        (ate)   (grass)                                 \n",
      "2    (goat)    (watched)     (cow)                                 \n",
      "3     (cow)        (ate)   (grass)                                 \n",
      "4    (goat)    (watched)     (cow)                                 \n",
      "5     (cow)        (ate)     (cow)  (watched)                      \n",
      "6    (goat)    (watched)     (cow)                                 \n",
      "7   (which)     (eating)   (grass)                                 \n",
      "8   (which)     (eating)                            (was)          \n",
      "9    (goat)  (attempted)   (grass)   (eating)                      \n",
      "10    (cow)        (ate)   (grass)                                 \n",
      "11    (cow)        (ate)  (butter)                                 \n",
      "12    (cow)        (ate)   (grass)      (ate)                      \n",
      "13    (cow)        (ate)     grass          _    _      _       _  \n",
      "14     goat          ate   (grass)                                 \n",
      "15    (cow)      (eaten)     grass          _    _      _       _  \n",
      "16     goat        eaten     grass          _    _      _       _  \n",
      "17     bird        eaten   (grass)                                 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21990/2693895187.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msov_table_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_subject_object_verb_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatcher_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msov_table_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_character_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msov_table_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21990/2510428027.py\u001b[0m in \u001b[0;36mplot_character_network\u001b[0;34m(sov_table_df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mverb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mverb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subj_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     char_net = nx.from_pandas_edgelist(\n",
      "\u001b[0;32m/tmp/ipykernel_21990/2510428027.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mverb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mverb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subj_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msov_table_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     char_net = nx.from_pandas_edgelist(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "sov_table_en = get_subject_object_verb_table(examples, nlp_en, matcher_en)\n",
    "print(sov_table_en)\n",
    "plot_character_network(sov_table_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c750f",
   "metadata": {},
   "source": [
    "## Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "248bce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1297821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple overweegt om voor 1 miljard een U.K. startup te kopen',\n",
       " \"Autonome auto's verschuiven de verzekeringverantwoordelijkheid naar producenten\",\n",
       " 'San Francisco overweegt robots op voetpaden te verbieden',\n",
       " 'Londen is een grote stad in het Verenigd Koninkrijk',\n",
       " 'Op brute wijze ving de schooljuf de quasi-kalme lynx']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_nl = load_spacy_pipeline(NL_SPACY_PIPELINE)\n",
    "\n",
    "matcher_nl = create_matcher(nlp_nl, NL_DEPENDENCY_PATTERN_FILE)\n",
    "\n",
    "EXTRA_SENT = \"Op brute wijze ving de schooljuf de quasi-kalme lynx\"\n",
    "if EXTRA_SENT not in nl_sentences:\n",
    "    nl_sentences.append(EXTRA_SENT)\n",
    "nl_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "579f7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = get_subject_object_verb_table(nl_sentences, nlp_nl, matcher_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfa4d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = combine_rows(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c7b93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>match_id</th>\n",
       "      <th>subj</th>\n",
       "      <th>verb</th>\n",
       "      <th>obj</th>\n",
       "      <th>comp</th>\n",
       "      <th>prep</th>\n",
       "      <th>aux</th>\n",
       "      <th>subjadj</th>\n",
       "      <th>objadj</th>\n",
       "      <th>obl</th>\n",
       "      <th>case</th>\n",
       "      <th>case_arg</th>\n",
       "      <th>objfixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple overweegt om voor 1 miljard een U.K. sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>(Apple)</td>\n",
       "      <td>(overweegt)</td>\n",
       "      <td>(U.K.)</td>\n",
       "      <td>(kopen)</td>\n",
       "      <td>om te</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(miljard)</td>\n",
       "      <td>(voor)</td>\n",
       "      <td>(1)</td>\n",
       "      <td>(startup)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonome auto's verschuiven de verzekeringvera...</td>\n",
       "      <td>4</td>\n",
       "      <td>(auto's)</td>\n",
       "      <td>(verschuiven)</td>\n",
       "      <td>(verzekeringverantwoordelijkheid)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco overweegt robots op voetpaden te...</td>\n",
       "      <td>6</td>\n",
       "      <td>(San, Francisco)</td>\n",
       "      <td>(overweegt)</td>\n",
       "      <td></td>\n",
       "      <td>(verbieden)</td>\n",
       "      <td>(te)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Londen is een grote stad in het Verenigd Konin...</td>\n",
       "      <td>8</td>\n",
       "      <td>(Londen)</td>\n",
       "      <td>(is)</td>\n",
       "      <td>(stad)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(grote)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Op brute wijze ving de schooljuf de quasi-kalm...</td>\n",
       "      <td>3</td>\n",
       "      <td>(schooljuf)</td>\n",
       "      <td>(ving)</td>\n",
       "      <td>(quasi-kalme)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>(wijze)</td>\n",
       "      <td>(Op)</td>\n",
       "      <td>(brute)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id sent_id                                               sent match_id  \\\n",
       "0      0       0  Apple overweegt om voor 1 miljard een U.K. sta...        1   \n",
       "1      1       0  Autonome auto's verschuiven de verzekeringvera...        4   \n",
       "2      2       0  San Francisco overweegt robots op voetpaden te...        6   \n",
       "3      3       0  Londen is een grote stad in het Verenigd Konin...        8   \n",
       "4      4       0  Op brute wijze ving de schooljuf de quasi-kalm...        3   \n",
       "\n",
       "               subj           verb                                obj  \\\n",
       "0           (Apple)    (overweegt)                             (U.K.)   \n",
       "1          (auto's)  (verschuiven)  (verzekeringverantwoordelijkheid)   \n",
       "2  (San, Francisco)    (overweegt)                                      \n",
       "3          (Londen)           (is)                             (stad)   \n",
       "4       (schooljuf)         (ving)                      (quasi-kalme)   \n",
       "\n",
       "          comp   prep aux subjadj   objadj        obl    case case_arg  \\\n",
       "0      (kopen)  om te                       (miljard)  (voor)      (1)   \n",
       "1                                                                        \n",
       "2  (verbieden)   (te)                                                    \n",
       "3                                  (grote)                               \n",
       "4                                             (wijze)    (Op)  (brute)   \n",
       "\n",
       "    objfixed  \n",
       "0  (startup)  \n",
       "1             \n",
       "2             \n",
       "3             \n",
       "4             "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e435f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table_combined = add_verb_group_column(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67fc7108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>match_id</th>\n",
       "      <th>subj_extended</th>\n",
       "      <th>verb group</th>\n",
       "      <th>obj_extended</th>\n",
       "      <th>means</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple overweegt om voor 1 miljard een U.K. sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>overweegt om te kopen</td>\n",
       "      <td>U.K. startup</td>\n",
       "      <td>voor 1 miljard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonome auto's verschuiven de verzekeringvera...</td>\n",
       "      <td>4</td>\n",
       "      <td>auto's</td>\n",
       "      <td>verschuiven</td>\n",
       "      <td>verzekeringverantwoordelijkheid</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco overweegt robots op voetpaden te...</td>\n",
       "      <td>6</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>overweegt te verbieden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Londen is een grote stad in het Verenigd Konin...</td>\n",
       "      <td>8</td>\n",
       "      <td>Londen</td>\n",
       "      <td>is</td>\n",
       "      <td>grote stad</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Op brute wijze ving de schooljuf de quasi-kalm...</td>\n",
       "      <td>3</td>\n",
       "      <td>schooljuf</td>\n",
       "      <td>ving</td>\n",
       "      <td>quasi-kalme</td>\n",
       "      <td>Op brute wijze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id sent_id                                               sent match_id  \\\n",
       "0      0       0  Apple overweegt om voor 1 miljard een U.K. sta...        1   \n",
       "1      1       0  Autonome auto's verschuiven de verzekeringvera...        4   \n",
       "2      2       0  San Francisco overweegt robots op voetpaden te...        6   \n",
       "3      3       0  Londen is een grote stad in het Verenigd Konin...        8   \n",
       "4      4       0  Op brute wijze ving de schooljuf de quasi-kalm...        3   \n",
       "\n",
       "    subj_extended               verb group                       obj_extended  \\\n",
       "0           Apple    overweegt om te kopen                       U.K. startup   \n",
       "1          auto's            verschuiven     verzekeringverantwoordelijkheid    \n",
       "2   San Francisco   overweegt te verbieden                                      \n",
       "3          Londen                     is                          grote stad    \n",
       "4       schooljuf                   ving                         quasi-kalme    \n",
       "\n",
       "            means  \n",
       "0  voor 1 miljard  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4  Op brute wijze  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58817237-c11c-4170-af8e-d5d43ed67bbd",
   "metadata": {},
   "source": [
    "Parser and tagger errors preventing correct analysis:\n",
    "1. sentence 1: `producenten` is attached to `verzekeringverantwoordelijkheid` instead of to `verschuiven`\n",
    "2. sentence 2: `robots op voetpaden` is not identified as object\n",
    "3. sentence 5: `lynx` is identified as a name (PROPN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d8d256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"nl\" id=\"5252d4fc0e1e45eba284e5b84c466b13-0\" class=\"displacy\" width=\"860\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Op</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">brute</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">wijze</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">ving</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">schooljuf</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">quasi-kalme</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">lynx</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 225.0,47.0 225.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-3\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,139.0 L422,127.0 438,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-4\" stroke-width=\"2px\" d=\"M340,137.0 C340,47.0 495.0,47.0 495.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M495.0,139.0 L503.0,127.0 487.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-6\" stroke-width=\"2px\" d=\"M340,137.0 C340,2.0 680.0,2.0 680.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M680.0,139.0 L688.0,127.0 672.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5252d4fc0e1e45eba284e5b84c466b13-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5252d4fc0e1e45eba284e5b84c466b13-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp_nl(nl_sentences[4]), style=\"dep\", options={\"distance\": 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd39ad1",
   "metadata": {},
   "source": [
    "## German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a20fd27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Die ganze Stadt ist ein Startup: Shenzhen ist das Silicon Valley fr Hardware-Firmen',\n",
       " 'Wie deutsche Startups die Technologie vorantreiben wollen: Knstliche Intelligenz',\n",
       " 'Trend zum Urlaub in Deutschland beschert Gastwirten mehr Umsatz',\n",
       " 'Bundesanwaltschaft erhebt Anklage gegen mutmalichen Schweizer Spion',\n",
       " 'San Francisco erwgt Verbot von Lieferrobotern',\n",
       " 'Autonome Fahrzeuge verlagern Haftpflicht auf Hersteller',\n",
       " 'Wo bist du?',\n",
       " 'Was ist die Hauptstadt von Deutschland?']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_de = load_spacy_pipeline(DE_SPACY_PIPELINE)\n",
    "\n",
    "matcher_de = create_matcher(nlp_de, DE_DEPENDENCY_PATTERN_FILE)\n",
    "\n",
    "de_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f53b8b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>match_id</th>\n",
       "      <th>subj</th>\n",
       "      <th>verb</th>\n",
       "      <th>obj</th>\n",
       "      <th>comp</th>\n",
       "      <th>prep</th>\n",
       "      <th>aux</th>\n",
       "      <th>subjadj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Die ganze Stadt ist ein Startup: Shenzhen ist ...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Stadt)</td>\n",
       "      <td>(ist)</td>\n",
       "      <td>(Startup)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Die ganze Stadt ist ein Startup: Shenzhen ist ...</td>\n",
       "      <td>1</td>\n",
       "      <td>(Shenzhen)</td>\n",
       "      <td>(ist)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Die ganze Stadt ist ein Startup: Shenzhen ist ...</td>\n",
       "      <td>1</td>\n",
       "      <td>(Valley)</td>\n",
       "      <td>(ist)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Wie deutsche Startups die Technologie vorantre...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Startups)</td>\n",
       "      <td>(wollen)</td>\n",
       "      <td>(Technologie)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Trend zum Urlaub in Deutschland beschert Gastw...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Trend)</td>\n",
       "      <td>(beschert)</td>\n",
       "      <td>(Gastwirten)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Trend zum Urlaub in Deutschland beschert Gastw...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Trend)</td>\n",
       "      <td>(beschert)</td>\n",
       "      <td>(Umsatz)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Bundesanwaltschaft erhebt Anklage gegen mutma...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Bundesanwaltschaft)</td>\n",
       "      <td>(erhebt)</td>\n",
       "      <td>(Anklage)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Bundesanwaltschaft erhebt Anklage gegen mutma...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Bundesanwaltschaft)</td>\n",
       "      <td>(erhebt)</td>\n",
       "      <td>(Spion)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco erwgt Verbot von Lieferrobotern</td>\n",
       "      <td>0</td>\n",
       "      <td>(Francisco)</td>\n",
       "      <td>(erwgt)</td>\n",
       "      <td>(Verbot)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonome Fahrzeuge verlagern Haftpflicht auf H...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Fahrzeuge)</td>\n",
       "      <td>(verlagern)</td>\n",
       "      <td>(Haftpflicht)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Autonome Fahrzeuge verlagern Haftpflicht auf H...</td>\n",
       "      <td>2</td>\n",
       "      <td>(Fahrzeuge)</td>\n",
       "      <td>(verlagern)</td>\n",
       "      <td>(Hersteller)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Wo bist du?</td>\n",
       "      <td>1</td>\n",
       "      <td>(du)</td>\n",
       "      <td>(bist)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Was ist die Hauptstadt von Deutschland?</td>\n",
       "      <td>0</td>\n",
       "      <td>(Was)</td>\n",
       "      <td>(ist)</td>\n",
       "      <td>(Hauptstadt)</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id sent_id                                               sent match_id  \\\n",
       "0       0       0  Die ganze Stadt ist ein Startup: Shenzhen ist ...        0   \n",
       "1       0       0  Die ganze Stadt ist ein Startup: Shenzhen ist ...        1   \n",
       "2       0       0  Die ganze Stadt ist ein Startup: Shenzhen ist ...        1   \n",
       "3       1       0  Wie deutsche Startups die Technologie vorantre...        0   \n",
       "4       2       0  Trend zum Urlaub in Deutschland beschert Gastw...        0   \n",
       "5       2       0  Trend zum Urlaub in Deutschland beschert Gastw...        0   \n",
       "6       3       0  Bundesanwaltschaft erhebt Anklage gegen mutma...        0   \n",
       "7       3       0  Bundesanwaltschaft erhebt Anklage gegen mutma...        2   \n",
       "8       4       0     San Francisco erwgt Verbot von Lieferrobotern        0   \n",
       "9       5       0  Autonome Fahrzeuge verlagern Haftpflicht auf H...        0   \n",
       "10      5       0  Autonome Fahrzeuge verlagern Haftpflicht auf H...        2   \n",
       "11      6       0                                        Wo bist du?        1   \n",
       "12      7       0            Was ist die Hauptstadt von Deutschland?        0   \n",
       "\n",
       "                    subj         verb            obj comp prep aux subjadj  \n",
       "0                (Stadt)        (ist)      (Startup)    _    _   _       _  \n",
       "1             (Shenzhen)        (ist)              _    _    _   _       _  \n",
       "2               (Valley)        (ist)              _    _    _   _       _  \n",
       "3             (Startups)     (wollen)  (Technologie)    _    _   _       _  \n",
       "4                (Trend)   (beschert)   (Gastwirten)    _    _   _       _  \n",
       "5                (Trend)   (beschert)       (Umsatz)    _    _   _       _  \n",
       "6   (Bundesanwaltschaft)     (erhebt)      (Anklage)    _    _   _       _  \n",
       "7   (Bundesanwaltschaft)     (erhebt)        (Spion)    _    _   _       _  \n",
       "8            (Francisco)     (erwgt)       (Verbot)    _    _   _       _  \n",
       "9            (Fahrzeuge)  (verlagern)  (Haftpflicht)    _    _   _       _  \n",
       "10           (Fahrzeuge)  (verlagern)   (Hersteller)    _    _   _       _  \n",
       "11                  (du)       (bist)              _    _    _   _       _  \n",
       "12                 (Was)        (ist)   (Hauptstadt)    _    _   _       _  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subject_object_verb_table(de_sentences, nlp_de, matcher_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48cb5dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"bf11a72a1a6e4583beb75ffb11994125-0\" class=\"displacy\" width=\"1025\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Die</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"125\">ganze</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"125\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">Stadt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"275\">ist</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"275\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">ein</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"425\">Startup:</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"425\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Shenzhen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">ist</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">das</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"725\">Silicon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"725\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">Valley</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"875\">fr</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"875\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">Hardware-Firmen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,77.0 190.0,77.0 190.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-1\" stroke-width=\"2px\" d=\"M145,152.0 C145,114.5 185.0,114.5 185.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M145,154.0 L137,142.0 153,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-2\" stroke-width=\"2px\" d=\"M220,152.0 C220,114.5 260.0,114.5 260.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M220,154.0 L212,142.0 228,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-3\" stroke-width=\"2px\" d=\"M370,152.0 C370,114.5 410.0,114.5 410.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-4\" stroke-width=\"2px\" d=\"M295,152.0 C295,77.0 415.0,77.0 415.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M415.0,154.0 L423.0,142.0 407.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-5\" stroke-width=\"2px\" d=\"M520,152.0 C520,114.5 560.0,114.5 560.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,154.0 L512,142.0 528,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-6\" stroke-width=\"2px\" d=\"M295,152.0 C295,2.0 575.0,2.0 575.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,154.0 L583.0,142.0 567.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-7\" stroke-width=\"2px\" d=\"M670,152.0 C670,77.0 790.0,77.0 790.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,154.0 L662,142.0 678,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-8\" stroke-width=\"2px\" d=\"M745,152.0 C745,114.5 785.0,114.5 785.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pnc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745,154.0 L737,142.0 753,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-9\" stroke-width=\"2px\" d=\"M595,152.0 C595,39.5 795.0,39.5 795.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M795.0,154.0 L803.0,142.0 787.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-10\" stroke-width=\"2px\" d=\"M820,152.0 C820,114.5 860.0,114.5 860.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mnr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M860.0,154.0 L868.0,142.0 852.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bf11a72a1a6e4583beb75ffb11994125-0-11\" stroke-width=\"2px\" d=\"M895,152.0 C895,114.5 935.0,114.5 935.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bf11a72a1a6e4583beb75ffb11994125-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M935.0,154.0 L943.0,142.0 927.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp_de(de_sentences[0]), style=\"dep\", options={\"distance\": 75})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d9bf8",
   "metadata": {},
   "source": [
    "When looking at the results of the dependency matcher and the parsing tree, it can be seen that the parser makes a few mistakes: In the first sentence, it erroneously labels \"Silicon Valley\" as a subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296986d3",
   "metadata": {},
   "source": [
    "## Danish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca1b4138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple overvejer at kbe et britisk startup for 1 milliard dollar.',\n",
       " 'Selvkrende biler flytter forsikringsansvaret over p producenterne.',\n",
       " 'San Francisco overvejer at forbyde udbringningsrobotter p fortovet.',\n",
       " 'London er en storby i Storbritannien.',\n",
       " 'Hvor er du?',\n",
       " 'Hvem er Frankrings president?',\n",
       " 'Hvad er hovedstaden i USA?',\n",
       " 'Hvornr blev Barack Obama fdt?',\n",
       " 'Hj bly gom vandt frk sexquiz p wc']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_da = load_spacy_pipeline(DA_SPACY_PIPELINE)\n",
    "\n",
    "matcher_da = create_matcher(nlp_da, DA_DEPENDENCY_PATTERN_FILE)\n",
    "\n",
    "EXTRA_SENT = \"Hj bly gom vandt frk sexquiz p wc\"\n",
    "if EXTRA_SENT not in da_sentences:\n",
    "    da_sentences.append(EXTRA_SENT)\n",
    "da_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec440bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sent</th>\n",
       "      <th>match_id</th>\n",
       "      <th>subj</th>\n",
       "      <th>verb</th>\n",
       "      <th>obj</th>\n",
       "      <th>comp</th>\n",
       "      <th>prep</th>\n",
       "      <th>aux</th>\n",
       "      <th>subjadj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple overvejer at kbe et britisk startup for...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Apple)</td>\n",
       "      <td>(overvejer)</td>\n",
       "      <td>(kbe)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple overvejer at kbe et britisk startup for...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Apple)</td>\n",
       "      <td>(overvejer)</td>\n",
       "      <td>(startup)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Selvkrende biler flytter forsikringsansvaret ...</td>\n",
       "      <td>3</td>\n",
       "      <td>(biler)</td>\n",
       "      <td>(flytter)</td>\n",
       "      <td>(producenterne)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco overvejer at forbyde udbringning...</td>\n",
       "      <td>0</td>\n",
       "      <td>(San)</td>\n",
       "      <td>(overvejer)</td>\n",
       "      <td>(forbyde)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco overvejer at forbyde udbringning...</td>\n",
       "      <td>0</td>\n",
       "      <td>(San)</td>\n",
       "      <td>(overvejer)</td>\n",
       "      <td>(udbringningsrobotter)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco overvejer at forbyde udbringning...</td>\n",
       "      <td>0</td>\n",
       "      <td>(Francisco)</td>\n",
       "      <td>(overvejer)</td>\n",
       "      <td>(forbyde)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>San Francisco overvejer at forbyde udbringning...</td>\n",
       "      <td>3</td>\n",
       "      <td>(San)</td>\n",
       "      <td>(overvejer)</td>\n",
       "      <td>(fortovet)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>London er en storby i Storbritannien.</td>\n",
       "      <td>5</td>\n",
       "      <td>(London)</td>\n",
       "      <td>(er)</td>\n",
       "      <td>(storby)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Hvem er Frankrings president?</td>\n",
       "      <td>5</td>\n",
       "      <td>(Hvem)</td>\n",
       "      <td>(er)</td>\n",
       "      <td>(president)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Hvornr blev Barack Obama fdt?</td>\n",
       "      <td>4</td>\n",
       "      <td>(Barack, Obama)</td>\n",
       "      <td>(fdt)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Hj bly gom vandt frk sexquiz p wc</td>\n",
       "      <td>0</td>\n",
       "      <td>(Hj)</td>\n",
       "      <td>(bly)</td>\n",
       "      <td>(sexquiz)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Hj bly gom vandt frk sexquiz p wc</td>\n",
       "      <td>2</td>\n",
       "      <td>(Hj)</td>\n",
       "      <td>(bly)</td>\n",
       "      <td>(gom)</td>\n",
       "      <td>(frk)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Hj bly gom vandt frk sexquiz p wc</td>\n",
       "      <td>2</td>\n",
       "      <td>(Hj)</td>\n",
       "      <td>(bly)</td>\n",
       "      <td>(wc)</td>\n",
       "      <td>(frk)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id sent_id                                               sent match_id  \\\n",
       "0       0       0  Apple overvejer at kbe et britisk startup for...        0   \n",
       "1       0       0  Apple overvejer at kbe et britisk startup for...        0   \n",
       "2       1       0  Selvkrende biler flytter forsikringsansvaret ...        3   \n",
       "3       2       0  San Francisco overvejer at forbyde udbringning...        0   \n",
       "4       2       0  San Francisco overvejer at forbyde udbringning...        0   \n",
       "5       2       0  San Francisco overvejer at forbyde udbringning...        0   \n",
       "6       2       0  San Francisco overvejer at forbyde udbringning...        3   \n",
       "7       3       0              London er en storby i Storbritannien.        5   \n",
       "8       5       0                      Hvem er Frankrings president?        5   \n",
       "9       7       0                    Hvornr blev Barack Obama fdt?        4   \n",
       "10      8       0               Hj bly gom vandt frk sexquiz p wc        0   \n",
       "11      8       0               Hj bly gom vandt frk sexquiz p wc        2   \n",
       "12      8       0               Hj bly gom vandt frk sexquiz p wc        2   \n",
       "\n",
       "               subj         verb                     obj    comp prep aux  \\\n",
       "0           (Apple)  (overvejer)                  (kbe)                    \n",
       "1           (Apple)  (overvejer)               (startup)                    \n",
       "2           (biler)    (flytter)         (producenterne)                    \n",
       "3             (San)  (overvejer)               (forbyde)                    \n",
       "4             (San)  (overvejer)  (udbringningsrobotter)                    \n",
       "5       (Francisco)  (overvejer)               (forbyde)                    \n",
       "6             (San)  (overvejer)              (fortovet)                    \n",
       "7          (London)         (er)                (storby)                    \n",
       "8            (Hvem)         (er)             (president)                    \n",
       "9   (Barack, Obama)       (fdt)                                            \n",
       "10            (Hj)        (bly)               (sexquiz)                    \n",
       "11            (Hj)        (bly)                   (gom)  (frk)            \n",
       "12            (Hj)        (bly)                    (wc)  (frk)            \n",
       "\n",
       "   subjadj  \n",
       "0           \n",
       "1           \n",
       "2           \n",
       "3           \n",
       "4           \n",
       "5           \n",
       "6           \n",
       "7           \n",
       "8           \n",
       "9           \n",
       "10          \n",
       "11          \n",
       "12          "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subject_object_verb_table(da_sentences, nlp_da, matcher_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8383e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"da\" id=\"525c7b026cde41c7bb337eb4bc13155d-0\" class=\"displacy\" width=\"1010\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">San</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Francisco</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">overvejer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">forbyde</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">udbringningsrobotter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">p</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">fortovet.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,62.0 285.0,62.0 285.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-1\" stroke-width=\"2px\" d=\"M190,182.0 C190,122.0 280.0,122.0 280.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,184.0 L182,172.0 198,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-2\" stroke-width=\"2px\" d=\"M430,182.0 C430,122.0 520.0,122.0 520.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-3\" stroke-width=\"2px\" d=\"M310,182.0 C310,62.0 525.0,62.0 525.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M525.0,184.0 L533.0,172.0 517.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-4\" stroke-width=\"2px\" d=\"M550,182.0 C550,122.0 640.0,122.0 640.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M640.0,184.0 L648.0,172.0 632.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-5\" stroke-width=\"2px\" d=\"M790,182.0 C790,122.0 880.0,122.0 880.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,184.0 L782,172.0 798,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-525c7b026cde41c7bb337eb4bc13155d-0-6\" stroke-width=\"2px\" d=\"M550,182.0 C550,2.0 890.0,2.0 890.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-525c7b026cde41c7bb337eb4bc13155d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M890.0,184.0 L898.0,172.0 882.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp_da(da_sentences[2]), style=\"dep\", options={\"distance\": 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7f4bd",
   "metadata": {},
   "source": [
    "The Danish parser also makes a few mistakes: For example, in the second sentence it labels both \"San\" and \"Francisco\" as separate subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9fa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
